## Spam Detector using DistilBERT
A lightweight spam classification system using Hugging Faceâ€™s distilbert-base-uncased.

## Highlights
Transformer-based binary classification (Spam vs Ham)

Uses Trainer API with validation & test evaluation

Real-time message prediction via console input

Performance: ~94% Test Accuracy

## Dataset
Cleaned & balanced spam/ham dataset (300 samples each)

Split: 70% Train, 15% Validation, 15% Test

## Tech Stack
transformers, datasets, scikit-learn, pandas

Fine-tuning DistilBERT using Hugging Face's Trainer
